%% Generate data part
clear all
clc
close all
t_max = 60;
x0 = abs(randn(1,1))*100; % = 1
[xt,yt] = generateData(t_max, x0); % dim(xt) = 61x1, dim(yt) = 60x1


%% Formulate prior
clc

%TODO: talk about this prior to Hedvig, is it to good?
number_of_samples = 1000;
x0 = 1; % TODO : change to random value.
[xt_prior,yt_prior] = generateData(number_of_samples,x0); % dim(xt) = 1x(t_max+1)

% To begin with, we set the prior to a normal distribution, generated by taking the mu and
% sigma from 1000 datapoints. 
% Another thought: maybe we should do this to get the prior but only on our
% real data points.

pd = fitdist(xt_prior,'Normal');
prior_mu = pd.mu;
prior_sigma = pd.sigma;

%% UPF Algorithm
% Repeat the experiment 100 times.

% SETTINGS
clc
% Set the number of time steps
T = 4; %T = 60;
% Set the number of particles
N = 10; %N = 200;
% Allocate memory for saving parameter values
particles = zeros(T+1,N);
Ps = zeros(T+1,N);
estimated_ys = zeros(T,N);
estimated_x_means = zeros(T+1,N);
importance_weights = zeros(T,N);

% INITIALIZATION, t = 0.
% Draw particles from the prior
particles(1,:) = normrnd(prior_mu, prior_sigma, 1, N); % 1xN
% Initiate noise variables
v0 = zeros(1,N);
n0 = zeros(1,N);
% Compute mean
estimated_x = mean(particles(1,:)); % 1x1
estimated_x_means(1,:) = estimated_x;
% Copute Covariance matrix.
diffs = particles(1,:) - estimated_x; % 1xN
P0 = diffs*diffs'; % 1x1
Ps(1,:) = P0; 
% Redefine the state rand var as a concatenation of the original state and
% noise variables.
[x_a, estimated_x_a, P0_a] = getCorrespondingAugmentedVariables(particles(1,:), v0, n0 ); % dim(x_a) = 3xN    dim(estimated_x_a) = 3x1    dim(P0_a) = 3x3

% THE BIG MACHINERY
% Define 
previous_estimated_x_a = estimated_x_a;
previous_P_a = P0_a;

alpha = 1;
beta = 0; % Comment from the paper: beta = 2 for suitable for Gaussian prior. Change to this?
kappa = 2; % Comment from the paper: kappa = 0 is a good default choise. Change to this?

% TODO: Adapt the content in the nestled loop to take the previous values
%       in each of the t:th steps. Not only using the original values. DONE?

for t = 1:T
    % a) Importance sampling step, using SUT.
    for i = 1:N
        % - Update the particles with the UKF:
        % * Calculate sigma points and their weights
        n_x = size(x_a,1);          % THESE PARAMETER definitions, should maybe be moved outside big loop?
        lambda = alpha^2 * (n_x + kappa) - n_x; 
        sqrt_matrix = sqrt((n_x+lambda)*previous_P_a); %3x3
        % Initialization
        previous_sigma_points = zeros(n_x,(2*n_x+1)); %3x7 
        previous_sigma_weights = zeros(2,(2*n_x+1)); %2x7 
        % The calculations
        previous_sigma_points(:,1) = previous_estimated_x_a;
        for sigma_point_i = 2:(n_x+1)
            previous_sigma_points(:,sigma_point_i) = previous_estimated_x_a + sqrt_matrix(:,sigma_point_i-1);
        end
        for sigma_point_i = (n_x+2):(2*n_x+1)
            previous_sigma_points(:,sigma_point_i) = previous_estimated_x_a - sqrt_matrix(:,sigma_point_i-4);
        end
        
        W0_m = lambda/(n_x+lambda);
        W0_c = lambda/(n_x+lambda) + (1 - alpha^2 + beta);
        previous_sigma_weights(1,1) = W0_m; 
        previous_sigma_weights(2,1) = W0_c; 
        previous_sigma_weights(1,2:(2*n_x+1)) = 1/(2*(n_x+lambda));
        previous_sigma_weights(2,2:(2*n_x+1)) = 1/(2*(n_x+lambda));
        
        % * Propagate particle into future (time update) 
        % Initialization
        current_sigma_points = zeros(n_x,(2*n_x+1)); %3x7 
        current_sigma_weights = zeros(2,(2*n_x+1)); %2x7 

        % The updates
        previous_sigma_x = previous_sigma_points(1,:);
        previous_sigma_v = previous_sigma_points(2,:);
        previous_sigma_n = previous_sigma_points(3,:);
        previous_t = t-1;

        current_sigma_points(1,:) = processModel(previous_sigma_x, previous_sigma_v, previous_t); % 1x7
        current_estimated_x = sum(previous_sigma_weights(1,:) .* current_sigma_points(1,:)); % 1x1
        current_P = sum(previous_sigma_weights(2,:) .* ((current_sigma_points(1,:)-current_estimated_x)*(current_sigma_points(1,:)-current_estimated_x)') ); %1x1
        current_sigma_point_propagations = observationModel(current_sigma_points(1,:),previous_sigma_n, t);% 1x7
        current_estimated_y = sum(previous_sigma_weights(1,:) .* current_sigma_point_propagations); % 1x1
        
        % * Incorporate new observation (measurement update)
        current_P_yy = sum(previous_sigma_weights(2,:) .* (current_sigma_point_propagations - current_estimated_y)*(current_sigma_point_propagations - current_estimated_y)' ); %1x1
        current_P_xy = sum(previous_sigma_weights(2,:) .* (current_sigma_points(1,:) - current_estimated_x)*(current_sigma_point_propagations - current_estimated_y)'); %1x1
        current_Kalman_gain = current_P_xy * inv(current_P_yy); %1x1
        current_estimated_x = current_estimated_x + current_Kalman_gain*(yt(t)-current_estimated_y);% 1x1    % CHANGE NAME on this variable?! 
        current_P = current_P - current_Kalman_gain*current_P_yy*current_Kalman_gain';% 1x1                  % CHANGE NAME on this variable?! 
        
        % - Sample x^
        new_particle = normrnd(current_estimated_x, current_P); % the (t+1) index is due to matlabs indexing, everywhere you see it.
        % - Set  
        particles(t+1,i) = new_particle;
        estimated_x_means(t+1,i) = current_estimated_x;
        Ps(t+1,i) = current_P;
    end  

    % TODO: Figure out it some how incorporate the noise distributions here
    % somewhere? Or if it they always are zero. And the distributions are
    % used only for generating data. I mean, v0 and n0 here below, really?? 
    
    % Evaluate the importance weights up to a normalizing constant.
    estimated_ys(t,:) = observationModel(particles(t,:), n0, t); %%% RIGHT??
    for i=1:N
        % the observation model is a Gaussian distribution
        
        obs_var = 1e-5;
        likelihood = (1/sqrt(2*pi*obs_var)) * exp(-0.5*(1/obs_var)*(yt(t)-estimated_ys(t,i))^2);
        % TODO: estimated_ys(t,i) is something else?
        % the process model is a Gamma distribution
        k = 3;
        theta = 2;
        x_term = particles(t+1,i)-particles(t,i); % Is this really correct? Feels weird, but according to the notation it should be like this...
        prior = (x_term^(k-1)*exp(-x_term/theta))/((theta^k)*gamma(k));
        % the proposal distribution
        proposal = (1/sqrt(2*pi*Ps(t+1,i))) * ...
            exp(-0.5*(1/Ps(t+1,i))*(particles(t+1,i)-estimated_x_means(t+1,i))^2);
        % the importance weight
        importance_weights(t,i) = likelihood*prior/proposal;
    end    
    % Normalize the importance weights.    
    importance_weights(t,:) = importance_weights(t,:) ./ ...
        sum(importance_weights(t,:));
    % ---------------------------------------
    % b) Selection step, resampling

    
    
end    







